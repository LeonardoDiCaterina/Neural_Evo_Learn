{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation Neural Networks - Learning and Implementation strategies\n",
    "\n",
    "In this notebook, we will study the use of `PyTorch` and `Tensorflow` frameworks for implementing and training Neural Networks. This is not intended to be exhaustive, but rather to provide examples for exploring the algorithms and their hyperparameters with these frameworks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR (exclusive OR) data simulation\n",
    "\n",
    "Let's run our examples for a very simple non-linear binary classification example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition sizes\n",
      "[torch.Size([150, 2]), torch.Size([150])] [torch.float32, torch.float32] [device(type='cpu'), device(type='cpu')]\n",
      "[torch.Size([50, 2]), torch.Size([50])] [torch.float32, torch.float32] [device(type='cpu'), device(type='cpu')]\n",
      "\n",
      "Batch sizes\n",
      "150\n",
      "1\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Data simulation\n",
    "N_data = 200\n",
    "train_size = 150\n",
    "X = 2 * torch.rand(N_data, 2, device=device, dtype=torch.float32) - 1\n",
    "y = torch.tensor([0 if elem[0]*elem[1] < 0 else 1 for elem in X], device=device, dtype=torch.float32)\n",
    "\n",
    "# Split training and test partitions\n",
    "X_train = X[:train_size, :]\n",
    "y_train = y[:train_size]\n",
    "X_val = X[train_size:, :]\n",
    "y_val = y[train_size:]\n",
    "\n",
    "# Define datasets for data loaders\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds = TensorDataset(X_val, y_val)\n",
    "\n",
    "# Create the data loaders\n",
    "batch_size_GD = train_size\n",
    "train_dl_GD = DataLoader(train_ds, batch_size_GD, shuffle=True)\n",
    "val_dl_GD = DataLoader(val_ds, batch_size_GD, shuffle=True)\n",
    "\n",
    "batch_size_SGD = 1\n",
    "train_dl_SGD = DataLoader(train_ds, batch_size_SGD, shuffle=True)\n",
    "val_dl_SGD = DataLoader(val_ds, batch_size_SGD, shuffle=True)\n",
    "\n",
    "batch_size_MiniSGD = 32\n",
    "train_dl_MniSGD = DataLoader(train_ds, batch_size_MiniSGD, shuffle=True)\n",
    "val_dl_MiniSGD = DataLoader(val_ds, batch_size_MiniSGD, shuffle=True)\n",
    "\n",
    "print('Partition sizes')\n",
    "print([X_train.shape, y_train.shape], [X_train.dtype, y_train.dtype], [X_train.device, y_train.device])\n",
    "print([X_val.shape, y_val.shape], [X_val.dtype, y_val.dtype], [X_val.device, y_val.device])\n",
    "\n",
    "print('\\nBatch sizes')\n",
    "print(batch_size_GD)\n",
    "print(batch_size_SGD)\n",
    "print(batch_size_MiniSGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "blue",
          "opacity": 0.35,
          "size": 9
         },
         "mode": "markers",
         "name": "Class 0",
         "type": "scatter",
         "x": {
          "bdata": "GPh/vlZoU79w8WU+cNIgv6BUg70AmM8+PKt3v7SaUT/IbxC+3qkRv6Cz977G4kM/eHd/v5JbLr9M2by+WFJWvwITa79K/gS/PIj4vjCahL5QscK+JqtTvyTzAD94+20+mDEdPgS1Ur9yYxa/pGsqv04IAD+se4E+Il8AP2Y3aT8eIWi/ejgnvxh7Q75cgLy+dDwKvyCZmr1It4o+oKRqvfwzaz8cDkY/xNWWPupxY7/ClQA/aBKsvjiXFT40vRW/GtMzP1hDcj54Xuo+dGAEv0CPDj2YTD0/ssBsP1gzZb9IiRq+IOngPSBd4b1wYNg9WqMdv2guSr/QXRm/HoUIv0hwNb6g2x0/qAkHP/jFcL8ICwe/EKUgvuqnDz9wZ0k/OLkMPvL7dD/AIfE9dNFiP3JxCL8wKjC+DPoDP6Knar/QZTa/gD4SvKwWET9QpoK9ID9rv9SDi76EnZG+/v1CPzAY4j5Yvro+SEUTv7Bxrr7sx5K+8IvCPuD/Dz5QcWe+qIYfv+xv8z6EnCm/CFgwP+wm8b6E1/q+gPJJP+AxGr4Ybu8+6G5HvlTrO7+C+g6/jOJnPw==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "8ADRPgRiCT/oREy+gD+jPQBTcz7cpPG+xIyLPqpfEr8kQFE/ONTiPmKnHj8oT3C+6OohP8L8Nj/U9tg+DrkSP9CE7z2A0V08BAUwP2Dc8T2A+qw+atN3P3haRb4M0HS/kOM8vtg2OD8gJdM9So5pP7iCJb9wfoS9NGPvvrC4pL2Qt70+8tEtP4SZHD8YXD4+DPCdPsBInT5AoOm8ULrjPQgNsb50g5y+YCeIvkCe0T0k1Ki+sOtXP0BDGb7+qmI/Pnc1v8DUwb2Qb6W+RI2APqSaRL9Aj5q++FFfv55bdD/IpWE+6qF/v4DH/z4KxW6/kC0nPvAx3z6GmDU/Vh0JP+SMhz5Umbu+kL2MvgwhIj9cVJ0+2LPsPhxq9b4AAxK9GDMCvkhPUr8aUSe/RlQNvwCcgz2wSic+gGGDvHBNPT6UgvI+uNMTP3DQxL4UWjs/EAJIP2TxSz/4a2g+EDqbvZTbBL/IT2m/putyP9jFfT8Addk82DdzvixxzL7g4K4+0IFFPsY7J7+YdGw+xnN8vwqDbj/gaxM+SgBDv2rYTj9WHnC/iBcePhJGMj++zBM/OMhLvg==",
          "dtype": "f4"
         }
        },
        {
         "marker": {
          "color": "red",
          "opacity": 0.35,
          "size": 9
         },
         "mode": "markers",
         "name": "Class 1",
         "type": "scatter",
         "x": {
          "bdata": "PLU2P0CJxj2g6my/PIY+v8JzFj8ASPw+2CTHPmSxrb6kI+6+aN5IvwDfYz7ke3k/MMYDvmAB1j0IEm4/QDs9vcjPVT7chwm/smdvv1DRiL48Od++0EjTPjSS6j6Aa5a+YB2HPQS/Ab+QjC4+8EdxvxioUz9icyo/wMVtvYDwlj2g+PC94sR4v0gELz/MOS6/QOZhPYAj7r3QKq49tEDkPgRfCb+ITkC+jBSOvtq7PT+UUcm+tHGRvmROdT8cPju/plEdv2CXRD3IRj8/PCe1PhBi+71EgM4+4NZpvQBGVz9YrVW+bHTrPvybLT9A3ns9kIRrvnZ8Qj/iF3i/hm1UP/BHTT5e0Sm/hO53P1Z4Ur9I1Go+YLnvPU6yb7+Us5I+YEzNvmR65z5ci7O+wJOpPeA3Gz+IoUm/wpJgv+CV776oZXk+/FvUvv4dNb9IQxa+oKpXvjgu0j4ohZ2+wDoCP0xOHb+wdcI9kC9wvg==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "UO4+P6AsSj7C5R+/0CLgvSxipz7wW3U+aCFPPqKBP7/4zTa+bsI+v2Tt3D6chUE/Yq9Kv8TpWj/wj2M/oOSUvrhm6j4g85C+yNR7v8p1F78Ckj6/iAxFPlgAAD/ElQK/qspVP+Tj6r5ImQ4/EGZ4vshFbT7C430/VNxPv/LwPz9YCA6+ygdlv/LkJj9g+fW+2ggzP8AEbL/8w5E+jNl8P4YWWr/U0jO/5upIv+C1Vj2g4my9xFXYvnB4eD+YIwu/gGr5vYRyBD8EUto+NEIiP7QJ076cN4k+iMg+vlRucz+Evpq+mEaWPsreDj+QNx0+VBDhvt4TZD/AzHi+Yo5JP7ZyWT+kHdm+ModzPwBnB744XJs+rM1tP5T91L5S+nw/pnkqv9AKHT6YPRa+VHWjPk7KFT9w8+295CEnv2BOgr082BI/KNwZv2SkW79EyMa+EKYtv1Qp4z54eeG+1jgcP1iEPb4A/Yk+XlsFvw==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "height": 400,
        "legend": {
         "x": 1,
         "y": 1
        },
        "margin": {
         "b": 20,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "shapes": [
         {
          "line": {
           "color": "black",
           "dash": "dot"
          },
          "type": "line",
          "x0": 0,
          "x1": 0,
          "y0": -1.75,
          "y1": 1.75
         },
         {
          "line": {
           "color": "black",
           "dash": "dot"
          },
          "type": "line",
          "x0": -1.75,
          "x1": 1.75,
          "y0": 0,
          "y1": 0
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 550,
        "xaxis": {
         "range": [
          -1.25,
          1.25
         ],
         "title": {
          "text": "$x_1$"
         }
        },
        "yaxis": {
         "range": [
          -1.25,
          1.25
         ],
         "title": {
          "text": "$x_2$"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X_np = X.cpu().numpy()\n",
    "y_np = y.cpu().numpy()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Class 0\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X_np[y_np == 0, 0],\n",
    "    y=X_np[y_np == 0, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(color='blue', size=9, opacity=0.35),\n",
    "    name='Class 0'\n",
    "))\n",
    "\n",
    "# Class 1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X_np[y_np == 1, 0],\n",
    "    y=X_np[y_np == 1, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(color='red', size=9, opacity=0.35),\n",
    "    name='Class 1'\n",
    "))\n",
    "\n",
    "fig.add_shape(type='line', x0=0, x1=0, y0=-1.75, y1=1.75, line=dict(color='black', dash='dot'))\n",
    "fig.add_shape(type='line', x0=-1.75, x1=1.75, y0=0, y1=0, line=dict(color='black', dash='dot'))\n",
    "fig.update_layout(\n",
    "    width=550,\n",
    "    height=400,\n",
    "    xaxis=dict(range=[-1.25, 1.25], title=r'$x_1$'),\n",
    "    yaxis=dict(range=[-1.25, 1.25], title=r'$x_2$'),\n",
    "    legend=dict(x=1, y=1),\n",
    "    margin=dict(l=20, r=20, t=20, b=20)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<hr />\n",
    "\n",
    "## 1. Building a Network with PyTorch\n",
    "\n",
    "Check the <a href='https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module'>PyTorch documentation</a> for details.\n",
    "\n",
    "To build a Neural Network in PyTorch, we create new Classes that inherit from the `nn.Module` class.\n",
    "\n",
    "This, some functionalities are already implemented. However, the model definitions have to be made mainly by hand. As a general rule, following the setps:\n",
    "\n",
    "1. Define the architecture of the network;\n",
    "2. Initialize the weights and biases of the network;\n",
    "3. Define the forward pass of the network;\n",
    "4. Define the training loop behaviour;\n",
    "5. Create the NN instance;\n",
    "6. Define the loss function;\n",
    "7. Define the optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1. Network architecture\n",
    "\n",
    "Let's create a NN with three **linear layers**:\n",
    "\n",
    "1. The first will upscale the 2 input layer nodes (2 features in the dataset) to 3 nodes.\n",
    "2. The second will upscale to 4 nodes.\n",
    "3. The third (output) will, then, downscale to 1 node.\n",
    "\n",
    "Besides that, the **activation functions** should be:\n",
    "\n",
    "1. The ReLU function in the hidden layer, and\n",
    "2. The sigmoid function in the output layer.\n",
    "\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Instantiate the parent (nn.Module) class\n",
    "        super(Net, self).__init__()\n",
    "    \n",
    "        # NN architecture definition\n",
    "        ...\n",
    "\n",
    "```\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Weights and bias initialization\n",
    "\n",
    "For the weights and bias initialization, let's use methods that are already available in the PyTorch library. However, notice that you can easily implement your own initialization methods.\n",
    "\n",
    "- Weights: let's use the Xavier Uniform Initialization method. It maintains the variance of the activations remain the same across the layers of the network.\n",
    "- Bias: bias will be initializes with zeros.\n",
    "\n",
    "Take a look at the PyTorch docs for more available initialization methods:\n",
    "<a href='https://pytorch.org/docs/stable/nn.init.html'>https://pytorch.org/docs/stable/nn.init.html</a>.\n",
    "\n",
    "```python\n",
    "torch.nn.init.xavier_uniform_(attribute.weight)\n",
    "torch.nn.init.zeros_(attribute.bias)\n",
    "\n",
    "```\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 3. Forward pass\n",
    "\n",
    "This step sets how the linear combination of the inputs and weights of each layer should work and how the combination of the linear step should be combined with the activation functions:\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "    # For each layer, the output will be the ReLu activation applied to the output of the linear operation\n",
    "    x = self.activation(self.fc1(x))\n",
    "    # For the last layer, the sigmoid function will be the activation\n",
    "    x = torch.sigmoid(self.fc2(x))\n",
    "    return x\n",
    "```\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 4. Training loop\n",
    "\n",
    "Having defined the Neural Network topology, the initialization method, and the feedforward pass, the behavior of the backpropagation should be set in the training loop.\n",
    "\n",
    "For that, Pytorch has some useful methods:\n",
    "\n",
    "- The `backward()` method calculates the derivative of the Error in respect to the NN weights applying the chain rule for hidden neurons;\n",
    "- The `step()` method updates the weights and bias based on the computed gradients.\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put steps 1 to 4 altogether:\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class Net_group_Y(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=2, output_size=1,\n",
    "                 hidden_layer_sizes=[3,4,5], activation=nn.ReLU()):\n",
    "        \n",
    "        super(Net_group_Y, self).__init__()\n",
    "        #\n",
    "        # 1. 1. Network architecture\n",
    "        \n",
    "        self.add_module(f'fc{1}', nn.Linear(input_size, hidden_layer_sizes[0]))\n",
    "        \n",
    "        for i in range(1,len(hidden_layer_sizes)):\n",
    "            self.add_module(f'fc{i+1}', nn.Linear(hidden_layer_sizes[i-1], hidden_layer_sizes[i]))\n",
    "        \n",
    "        self.add_module(f'fc{len(hidden_layer_sizes) +1 }', nn.Linear(hidden_layer_sizes[-1], output_size))\n",
    "\n",
    "        # Weights initialisation\n",
    "        # The apply method applies the function passed as the apply() argument\n",
    "        # to each element in the object, that in this case is the neural network.\n",
    "        self.apply(self._init_weights)\n",
    "        # Store the parameters\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.n_forward_calls = 0\n",
    "        \n",
    "    #\n",
    "    # 1. 2. Weights and bias initialization\n",
    "    #\n",
    "    def _init_weights(self, attribute):\n",
    "        if isinstance(attribute, nn.Linear):\n",
    "          torch.nn.init.xavier_uniform_(attribute.weight)\n",
    "          torch.nn.init.zeros_(attribute.bias)\n",
    "    #\n",
    "    # 1. 3. Forward pass\n",
    "    \"\"\"    \n",
    "    def forward(self, x):\n",
    "        # For each layer, the output will be the ReLu activation applied to the output of the linear operation\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        # For the last layer, the sigmoid function will be the activation\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through all layers\n",
    "        for i in range(1, len(self.hidden_layer_sizes) + 2):\n",
    "            #print(f'forward pass layer {i}')\n",
    "            layer = getattr(self, f'fc{i}')\n",
    "            x = layer(x)\n",
    "            if i < len(self.hidden_layer_sizes):\n",
    "                self.n_forward_calls += 1\n",
    "                x = self.activation(x)\n",
    "        # Apply sigmoid activation to the output layer\n",
    "        self.n_forward_calls += 1\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    #\n",
    "    # 1. 4. Training loop\n",
    "    # For details, see Machine Learning with PyTorch and Scikit-Learn.\n",
    "    #\n",
    "    def train(self, num_epochs, loss_fn, optimizer, train_dl, train_size, batch_size, x_valid, y_valid):\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "        # Loss and accuracy history objects initialization\n",
    "        loss_hist_train = [0] * num_epochs\n",
    "        accuracy_hist_train = [0] * num_epochs\n",
    "        loss_hist_valid = [0] * num_epochs\n",
    "        accuracy_hist_valid = [0] * num_epochs\n",
    "        delta_times = [0] * num_epochs\n",
    "        self.n_forward_calls = 0\n",
    "        \n",
    "        # Learning loop\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            start_time = time.time()\n",
    "            # Batch learn\n",
    "            for x_batch, y_batch in train_dl:\n",
    "                #print('*'*20)\n",
    "                # ---\n",
    "                # 1.4.1. Get the predictions, the [:,0] reshapes from (batch_size,1) to (batch_size)\n",
    "                pred = self(x_batch)[:,0]\n",
    "                # 1.4.2. Compute the loss\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                # 1.4.3. Back propagate the gradients\n",
    "                # The `backward()` method, already available in PyTroch, calculates the \n",
    "                # derivative of the Error in respect to the NN weights\n",
    "                # applying the chain rule for hidden neurons.\n",
    "                loss.backward()\n",
    "                # 1.4.4. Update the weights based on the computed gradients\n",
    "                optimizer.step()\n",
    "                # ---\n",
    "                \n",
    "                # Reset to zero the gradients so they will not accumulate over the mini-batches\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Update performance metrics\n",
    "                loss_hist_train[epoch] += loss.item()\n",
    "                is_correct = ((pred>=0.5).float() == y_batch).float()\n",
    "                accuracy_hist_train[epoch] += is_correct.mean()\n",
    "            \n",
    "            delta_times[epoch] = time.time() - start_time\n",
    "            # Average the results\n",
    "            loss_hist_train[epoch] /= train_size/batch_size\n",
    "            accuracy_hist_train[epoch] /= train_size/batch_size\n",
    "            \n",
    "            # Predict the validation set\n",
    "            pred = self(x_valid)[:, 0]\n",
    "            loss_hist_valid[epoch] = loss_fn(pred, y_valid).item()\n",
    "            is_correct = ((pred>=0.5).float() == y_valid).float()\n",
    "            accuracy_hist_valid[epoch] += is_correct.mean()\n",
    "            \n",
    "        return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid, self.n_forward_calls, delta_times\n",
    "\n",
    "    # Not needed normaly, it is just for mlextend plots\n",
    "    def predict(self, x):\n",
    "        print(f'predict with input shape: {x.shape}')\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        pred = self.forward(x)[:, 0]\n",
    "        print(f'finished predict with output shape: {pred.shape}')\n",
    "        return (pred>=0.5).float()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 96.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "********************\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n",
      "forward pass layer 1\n",
      "forward pass layer 2\n",
      "forward pass layer 3\n",
      "forward pass layer 4\n",
      "forward pass layer 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "\n",
    "criterion = RMSELoss()\n",
    "\n",
    "class nn_model():\n",
    "    def __init__(self,\n",
    "                X_train,\n",
    "                X_val,\n",
    "                y_train,\n",
    "                y_val,\n",
    "                input_size, \n",
    "                output_size,\n",
    "                hidden_layer_sizes, \n",
    "                optimizer,\n",
    "                num_epochs,\n",
    "                train_dl,  \n",
    "                train_size,\n",
    "                batch_size,\n",
    "                learning_rate,\n",
    "                activation=nn.ReLU()):\n",
    "        \n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_dl = train_dl\n",
    "        self.train_size = train_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.arcthicture = Net_group_Y(input_size=input_size,\n",
    "                                  output_size=output_size,\n",
    "                                  hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                  activation=activation)\n",
    "        \n",
    "        self.arcthicture.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.fitness, self.test_fitness, self.accuracy, self.accuracy_valid, self.n_forward_calls, self.delta_times = self.fit(X_train, X_val, y_train, y_val, arcthicture=self.arcthicture,\n",
    "                num_epochs=num_epochs, \n",
    "                loss_fn=criterion, \n",
    "                optimizer_name=optimizer,\n",
    "                batch_size=batch_size, \n",
    "                learning_rate=learning_rate)\n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "    def fit(self,X_train,X_val,y_train,y_val,\n",
    "                num_epochs, loss_fn, optimizer_name, batch_size, learning_rate):\n",
    "        \"\"\"\n",
    "        Train the model with the given parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - num_epochs: Number of epochs to train the model.\n",
    "        - loss_fn: Loss function to use for training.\n",
    "        - optimizer: Optimizer to use for training.\n",
    "        - batch_size: Size of each batch during training.\n",
    "        - x_valid: Validation input data.\n",
    "        - y_valid: Validation target data.\n",
    "        - learning_rate: Learning rate for the optimizer.\n",
    "        \n",
    "        Returns:\n",
    "        - history: Training history containing loss and accuracy metrics.\n",
    "        \"\"\"\n",
    "\n",
    "        # Define datasets for data loaders\n",
    "        train_ds = TensorDataset(X_train, y_train)\n",
    "        val_ds = TensorDataset(X_val, y_val)\n",
    "\n",
    "        train_size = len(train_ds)\n",
    "        if optimizer_name == 'GD':\n",
    "            batch_size = train_size\n",
    "            train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "            #val_dl = DataLoader(val_ds, batch_size, shuffle=True)\n",
    "        \n",
    "        elif optimizer_name == 'SGD':\n",
    "            batch_size = 1\n",
    "            train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "            #val_dl = DataLoader(val_ds, batch_size, shuffle=True)\n",
    "\n",
    "        else:\n",
    "            batch_size = batch_size\n",
    "            train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "            #val_dl = DataLoader(val_ds, batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer_choiche = {\n",
    "        'GD': torch.optim.SGD(self.arcthicture.parameters(), lr=learning_rate),\n",
    "        'SGD': torch.optim.SGD(self.arcthicture.parameters(), lr=learning_rate),\n",
    "        'MiniSGD': torch.optim.SGD(self.arcthicture.parameters(), lr=learning_rate),\n",
    "        'ASGD': torch.optim.ASGD(self.arcthicture.parameters(), lr=learning_rate),\n",
    "        \n",
    "        'RMSprop': torch.optim.RMSprop(self.arcthicture.parameters(), lr=learning_rate),\n",
    "        'Adam': torch.optim.Adam(self.arcthicture.parameters(), lr=learning_rate)\n",
    "        }\n",
    "        optimizer_instance = optimizer_choiche[optimizer_name]\n",
    "        \n",
    "        return self.arcthicture.train(\n",
    "            num_epochs=num_epochs, \n",
    "            loss_fn=loss_fn, \n",
    "            optimizer=optimizer_instance, \n",
    "            train_dl=train_dl, \n",
    "            train_size=train_size, \n",
    "            batch_size=batch_size,\n",
    "            x_valid=val_ds[0],\n",
    "            y_valid=val_ds[1])\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CIFO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
