{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83deb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import itertools\n",
    "import json\n",
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Slim-GSGP imports\n",
    "from slim_gsgp.datasets.data_loader import load_pandas_df  \n",
    "from slim_gsgp.utils.utils import train_test_split  \n",
    "from slim_gsgp.main_gp import gp\n",
    "#from slim_gsgp.main_gsgp import gsgp\n",
    "from slim_gsgp.main_slim import slim\n",
    "from slim_gsgp.evaluators.fitness_functions import rmse\n",
    "\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import itertools \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0410435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.chdir(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207cfae3",
   "metadata": {},
   "source": [
    "## Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccb91e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_GridSearch(gp_model, fixed_params, param_grid, seed):\n",
    "    models = []\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for combo in product(*values):\n",
    "        dynamic_params = dict(zip(keys, combo))\n",
    "        full_params = {**fixed_params, **dynamic_params}\n",
    "        model = gp_model(**full_params, seed=seed)\n",
    "        res = {'model': model}\n",
    "        res.update({'rmse_train': model.fitness.item()})\n",
    "        res.update({'rmse_test': model.test_fitness.item()})\n",
    "        res.update({'dynamic_params': dynamic_params})\n",
    "        models.append(res)\n",
    "    return models      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a86130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_median_rmse(results_data):\n",
    "    \"\"\"\n",
    "    Groups results by 'dynamic_params' and calculates the median 'rmse_test' for each group.\n",
    "\n",
    "    Args:\n",
    "        results_data (list): A list of lists, where each inner list contains dictionaries\n",
    "                             with 'dynamic_params' and 'rmse_test' keys.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing:\n",
    "              {'dynamic_params': {...}, 'rmse_test_median': float}\n",
    "    \"\"\"\n",
    "\n",
    "    #Flatten the list of lists into a single list of dictionaries\n",
    "    flattened_results = list(itertools.chain.from_iterable(results_data))\n",
    "\n",
    "\n",
    "    grouped_scores_data = {}\n",
    "\n",
    "    for item in flattened_results:\n",
    "        dynamic_params_dict = item['dynamic_params']\n",
    "        rmse_test = item['rmse_test']\n",
    "\n",
    "        # Sort params to ensure consistency \n",
    "        # Convert to tuple to make it hashable, and so able to be used as a dictionary key \n",
    "        hashable_dynamic_params = tuple(sorted(dynamic_params_dict.items()))\n",
    "\n",
    "        # Check if combination does not exist in the dictionary\n",
    "        if hashable_dynamic_params not in grouped_scores_data:\n",
    "\n",
    "            # Create entry if not\n",
    "            grouped_scores_data[hashable_dynamic_params] = {\n",
    "                'dynamic_params': dynamic_params_dict, \n",
    "                'rmse_test': []\n",
    "            }\n",
    "        grouped_scores_data[hashable_dynamic_params]['rmse_test'].append(rmse_test)\n",
    "\n",
    "    # Calculate median for each group and format output\n",
    "    final_output = []\n",
    "    for group_info in grouped_scores_data.values():\n",
    "        combination = group_info['dynamic_params']\n",
    "        rmse_scores = group_info['rmse_test']\n",
    "\n",
    "        # Calculate median RMSE\n",
    "        median_rmse = statistics.median(rmse_scores)\n",
    "        final_output.append({\n",
    "            'dynamic_params': combination,\n",
    "            'rmse_test_median': median_rmse\n",
    "        })\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80efa210",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "820ba804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the desired dataset\n",
    "df = pd.read_csv(\"../data/sustavianfeed.csv\", sep=';')\n",
    "\n",
    "# Dropping the first column (index) and renaming the columns\n",
    "df = df.drop(columns= ['WING TAG', 'EMPTY MUSCULAR STOMACH'])\n",
    "\n",
    "# Moving crude protein to the end of the dataframe\n",
    "df = df[[col for col in df.columns if col != 'CRUDE PROTEIN'] + ['CRUDE PROTEIN']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3f831",
   "metadata": {},
   "source": [
    "# Nested CV with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47c6c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    " \n",
    "# Edit the name and log directory based on the model you want to run\n",
    "\n",
    "#MODEL_NAME = 'GP'\n",
    "#MODEL_NAME = 'GSGP'\n",
    "MODEL_NAME = 'SLIM-GSGP'\n",
    "\n",
    "DATASET_NAME = MODEL_NAME +'_sustavianfeed'\n",
    "LOG_DIR = './log/' + MODEL_NAME + '/'\n",
    "\n",
    "LOG_LEVEL = 2\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5007d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_outer = 5\n",
    "k_inner = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d600cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning df into X and y torch.Tensors\n",
    "X, y = load_pandas_df(df, X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab3d1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Instances:\t96\n",
      "--\n",
      "Outer Train set:\t77\n",
      "Test set:\t\t19\n",
      "--\n",
      "Inner Train set:\t52\n",
      "Validation set:\t\t25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FITNESS_FUNCTION = 'rmse'\n",
    "MINIMIZATION = True\n",
    "\n",
    "total_instances = X.shape[0]\n",
    "outer_test_size = total_instances // k_outer\n",
    "outer_train_size = total_instances - outer_test_size\n",
    "inner_val_size = outer_train_size // k_inner\n",
    "inner_train_size = outer_train_size - inner_val_size\n",
    "\n",
    "print(f'Total Instances:\\t{total_instances}\\n--')\n",
    "print(f'Outer Train set:\\t{outer_train_size}')\n",
    "print(f'Test set:\\t\\t{outer_test_size}\\n--')\n",
    "print(f'Inner Train set:\\t{inner_train_size}')\n",
    "print(f'Validation set:\\t\\t{inner_val_size}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fce2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 20\n",
    "\n",
    "fixed_params = {\n",
    "    # ---\n",
    "    # Search Space\n",
    "    'initializer': 'rhh',\n",
    "    'init_depth': 2,\n",
    "    'tree_constants': [random.uniform(0, 1) for _ in range(9)]+[ -1.], \n",
    "    'tree_functions': ['add', 'subtract'],\n",
    "    'prob_const': 0.1,\n",
    "    # ---\n",
    "    # Problem Instance\n",
    "    'dataset_name': DATASET_NAME,\n",
    "    'fitness_function': 'rmse',\n",
    "    'minimization': True,\n",
    "    # ---\n",
    "    # Model instance \n",
    "    'tournament_size': int(POP_SIZE*0.02) if POP_SIZE>100 else 2,\n",
    "    'pop_size': POP_SIZE,\n",
    "    'ms_lower': 0,\n",
    "    'ms_upper': 0.5,\n",
    "    'reconstruct': False,\n",
    "    # ---\n",
    "    # Solve settings\n",
    "    'n_iter': 500,\n",
    "    'elitism': True,\n",
    "    'n_elites': 2, \n",
    "    'test_elite': True,\n",
    "    'log_level': LOG_LEVEL,\n",
    "    'verbose': 0,\n",
    "    'n_jobs': 1,\n",
    "\n",
    "    # ---\n",
    "    # GP unique settings\n",
    "    #'max_depth': 10, \n",
    "    #'p_xo' : 0.5,\n",
    "\n",
    "    # ---\n",
    "    # GSGP unique settings\n",
    "    \n",
    "\n",
    "    # ---\n",
    "    # SLIM unique settings\n",
    "    'max_depth': 10,\n",
    "    'p_inflate': 0.70,\n",
    "    #'slim_version': 'SLIM+SIG2',\n",
    "    #'copy_parent': True,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "SLIM_VERSIONS = ['SLIM+SIG2', 'SLIM+SIG1', 'SLIM+ABS', 'SLIM*SIG2', 'SLIM*SIG1', 'SLIM*ABS']\n",
    "\n",
    "param_grid = {\n",
    "    'slim_version': SLIM_VERSIONS,\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5b10a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_nested_cross_validation(X, y, gp_model,  k_outer, k_inner, fixed_params, param_grid, seed, LOG_DIR, DATASET_NAME):\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation for a given model and dataset.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): Feature matrix.\n",
    "        y (torch.Tensor): Target vector.\n",
    "        gp_model (callable): The gp model to be evaluated.\n",
    "        k_outer (int): Number of outer folds.\n",
    "        k_inner (int): Number of inner folds.\n",
    "        fixed_params (dict): Fixed parameters for the model.\n",
    "        param_grid (dict): Parameter grid for hyperparameter tuning.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries containing model results.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    cv_outer = KFold(n_splits=k_outer, random_state=seed, shuffle=True)\n",
    "    cv_inner = KFold(n_splits=k_inner, random_state=seed, shuffle=True)\n",
    "\n",
    "    data_cv_outer = [[learning_ix, test_ix] for learning_ix, test_ix in cv_outer.split(X, y)]\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for i, (train_ix, test_ix) in enumerate(data_cv_outer):\n",
    "        print(f'Outer fold {i+1}/{k_outer}')\n",
    "        X_learning, y_learning = X[train_ix], y[train_ix]\n",
    "        X_test, y_test = X[test_ix], y[test_ix]\n",
    "\n",
    "        # Inner cross-validation\n",
    "        results = []    \n",
    "\n",
    "        data_cv_inner = [[learning_ix, val_ix] for learning_ix, val_ix in cv_inner.split(X_learning, y_learning)]\n",
    "        for j, (train_ix, val_ix) in enumerate(data_cv_inner):\n",
    "\n",
    "            # Split the data into training and validation sets K times \n",
    "            print(f'-----\\n Inner fold {j+1}/{k_inner}')\n",
    "            X_inner_train, y_inner_train = X_learning[train_ix], y_learning[train_ix]\n",
    "            X_inner_val, y_inner_val = X_learning[val_ix], y_learning[val_ix]\n",
    "\n",
    "            print(f'Training shape: {X_inner_train.shape}\\nValidation shape: {X_inner_val.shape}\\n')\n",
    "\n",
    "            # Update the X and y values in the fixed_params dictionary\n",
    "            fixed_params.update({\n",
    "                'X_train': X_inner_train, 'y_train': y_inner_train,\n",
    "                'X_test': X_inner_val, 'y_test': y_inner_val\n",
    "            })\n",
    "\n",
    "            # Update LOG_PATH in the fixed_params dictionary\n",
    "            LOG_PATH = LOG_DIR+DATASET_NAME+'_'+'outer'+'_'+str(i)+'_'+'inner'+'_'+str(j)+'.csv'\n",
    "            if os.path.exists(LOG_PATH):\n",
    "                os.remove(LOG_PATH)\n",
    "            fixed_params.update({'log_path': LOG_PATH})\n",
    "\n",
    "\n",
    "            res = fit_model_GridSearch(gp_model=gp_model, fixed_params=fixed_params, param_grid=param_grid, seed=(seed+k_inner))\n",
    "            \n",
    "            # Log\n",
    "            results.append(res)\n",
    "\n",
    "        medians = group_and_median_rmse(results) \n",
    "\n",
    "        # Find minimum median rmse\n",
    "        best_dynamic_combo_median = min(medians, key=lambda x: x['rmse_test_median'])\n",
    "\n",
    "        print(f'Best inner combination: {best_dynamic_combo_median[\"dynamic_params\"]} with median RMSE: {best_dynamic_combo_median[\"rmse_test_median\"]}')\n",
    "\n",
    "        # Train the best model on the entire training set\n",
    "        print('Training best combination on entire learning set')\n",
    "\n",
    "        best_hyper_combo = best_dynamic_combo_median['dynamic_params']\n",
    "\n",
    "        fixed_params.update({\n",
    "                'X_train': X_learning, 'y_train': y_learning,\n",
    "                'X_test': X_test, 'y_test': y_test\n",
    "            })\n",
    "        \n",
    "        LOG_PATH = LOG_DIR+DATASET_NAME+'_'+'outer'+'_'+str(i)+'.csv'\n",
    "        if os.path.exists(LOG_PATH):\n",
    "            os.remove(LOG_PATH)\n",
    "    \n",
    "        fixed_params.update({'log_path': LOG_PATH})\n",
    "        \n",
    "        full_params = {**fixed_params, **best_hyper_combo}\n",
    "\n",
    "        outer_model = gp_model(**full_params, seed=(seed+k_outer))\n",
    "\n",
    "        res = {'model': outer_model}  \n",
    "        res.update({'rmse_train': outer_model.fitness.item()})\n",
    "        res.update({'rmse_test': outer_model.test_fitness.item()})\n",
    "        res.update({'dynamic_params': best_hyper_combo})\n",
    "\n",
    "        models.append(res)\n",
    "\n",
    "    return models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c07ded42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1/5\n",
      "-----\n",
      " Inner fold 1/3\n",
      "Training shape: torch.Size([50, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 2/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([25, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 3/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([25, 12])\n",
      "\n",
      "Best inner combination: {'slim_version': 'SLIM*ABS'} with median RMSE: 12.191201210021973\n",
      "Training best combination on entire learning set\n",
      "Outer fold 2/5\n",
      "-----\n",
      " Inner fold 1/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 2/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 3/3\n",
      "Training shape: torch.Size([52, 12])\n",
      "Validation shape: torch.Size([25, 12])\n",
      "\n",
      "Best inner combination: {'slim_version': 'SLIM*SIG2'} with median RMSE: 14.297585487365723\n",
      "Training best combination on entire learning set\n",
      "Outer fold 3/5\n",
      "-----\n",
      " Inner fold 1/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 2/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 3/3\n",
      "Training shape: torch.Size([52, 12])\n",
      "Validation shape: torch.Size([25, 12])\n",
      "\n",
      "Best inner combination: {'slim_version': 'SLIM*SIG2'} with median RMSE: 15.469388961791992\n",
      "Training best combination on entire learning set\n",
      "Outer fold 4/5\n",
      "-----\n",
      " Inner fold 1/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 2/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 3/3\n",
      "Training shape: torch.Size([52, 12])\n",
      "Validation shape: torch.Size([25, 12])\n",
      "\n",
      "Best inner combination: {'slim_version': 'SLIM*SIG2'} with median RMSE: 12.418806076049805\n",
      "Training best combination on entire learning set\n",
      "Outer fold 5/5\n",
      "-----\n",
      " Inner fold 1/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 2/3\n",
      "Training shape: torch.Size([51, 12])\n",
      "Validation shape: torch.Size([26, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 3/3\n",
      "Training shape: torch.Size([52, 12])\n",
      "Validation shape: torch.Size([25, 12])\n",
      "\n",
      "Best inner combination: {'slim_version': 'SLIM*SIG1'} with median RMSE: 12.488411903381348\n",
      "Training best combination on entire learning set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': <slim_gsgp.algorithms.SLIM_GSGP.representations.individual.Individual at 0x1bdfe41e2b0>,\n",
       "  'rmse_train': 12.13796329498291,\n",
       "  'rmse_test': 20.066356658935547,\n",
       "  'dynamic_params': {'slim_version': 'SLIM*ABS'}},\n",
       " {'model': <slim_gsgp.algorithms.SLIM_GSGP.representations.individual.Individual at 0x1bdfe41e150>,\n",
       "  'rmse_train': 11.974928855895996,\n",
       "  'rmse_test': 12.361209869384766,\n",
       "  'dynamic_params': {'slim_version': 'SLIM*SIG2'}},\n",
       " {'model': <slim_gsgp.algorithms.SLIM_GSGP.representations.individual.Individual at 0x1bdfe41c680>,\n",
       "  'rmse_train': 12.581201553344727,\n",
       "  'rmse_test': 10.441032409667969,\n",
       "  'dynamic_params': {'slim_version': 'SLIM*SIG2'}},\n",
       " {'model': <slim_gsgp.algorithms.SLIM_GSGP.representations.individual.Individual at 0x1bdfe41dc80>,\n",
       "  'rmse_train': 12.042012214660645,\n",
       "  'rmse_test': 12.532037734985352,\n",
       "  'dynamic_params': {'slim_version': 'SLIM*SIG2'}},\n",
       " {'model': <slim_gsgp.algorithms.SLIM_GSGP.representations.individual.Individual at 0x1bdfe41d5a0>,\n",
       "  'rmse_train': 12.349873542785645,\n",
       "  'rmse_test': 12.710312843322754,\n",
       "  'dynamic_params': {'slim_version': 'SLIM*SIG1'}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_nested_cross_validation(X, y, gp_model=slim, k_outer=k_outer, k_inner=k_inner, fixed_params=fixed_params, param_grid=param_grid, seed=seed, LOG_DIR=LOG_DIR, DATASET_NAME=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576c88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c5c00bd",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20994d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# project_root = r\"c:\\Users\\irism\\OneDrive - NOVAIMS\\Msc-NEL\\Neural_Evo_Learn\"\n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.insert(0, project_root)  # Add to start of path\n",
    "\n",
    "from utils.visualization_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_best_combs(model_name='GSGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2911d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best_combs(model_name='GSGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac574506",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_size_per_outer(k_outer=10, model_name='GSGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_size_per_comb(10, 'GSGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "niche_entropy(k_outer=10, model_name='GSGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_fitness_diversity(10, 'GSGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bcbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
