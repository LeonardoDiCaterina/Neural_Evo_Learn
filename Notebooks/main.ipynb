{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83deb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import itertools\n",
    "import json\n",
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Slim-GSGP imports\n",
    "from slim_gsgp.datasets.data_loader import load_pandas_df  \n",
    "from slim_gsgp.utils.utils import train_test_split  \n",
    "from slim_gsgp.main_gp import gp\n",
    "#from slim_gsgp.main_gsgp import gsgp\n",
    "from slim_gsgp.main_slim import slim\n",
    "from slim_gsgp.evaluators.fitness_functions import rmse\n",
    "\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import itertools \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0410435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.chdir(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207cfae3",
   "metadata": {},
   "source": [
    "## Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccb91e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_GridSearch(gp_model, fixed_params, param_grid, seed):\n",
    "    models = []\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for combo in product(*values):\n",
    "        dynamic_params = dict(zip(keys, combo))\n",
    "        full_params = {**fixed_params, **dynamic_params}\n",
    "        model = gp_model(**full_params, seed=seed)\n",
    "        res = {'model': model}\n",
    "        res.update({'rmse_train': model.fitness.item()})\n",
    "        res.update({'rmse_test': model.test_fitness.item()})\n",
    "        res.update({'dynamic_params': dynamic_params})\n",
    "        models.append(res)\n",
    "    return models      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a86130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_median_rmse(results_data):\n",
    "    \"\"\"\n",
    "    Groups results by 'dynamic_params' and calculates the median 'rmse_test' for each group.\n",
    "\n",
    "    Args:\n",
    "        results_data (list): A list of lists, where each inner list contains dictionaries\n",
    "                             with 'dynamic_params' and 'rmse_test' keys.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing:\n",
    "              {'dynamic_params': {...}, 'rmse_test_median': float}\n",
    "    \"\"\"\n",
    "\n",
    "    #Flatten the list of lists into a single list of dictionaries\n",
    "    flattened_results = list(itertools.chain.from_iterable(results_data))\n",
    "\n",
    "\n",
    "    grouped_scores_data = {}\n",
    "\n",
    "    for item in flattened_results:\n",
    "        dynamic_params_dict = item['dynamic_params']\n",
    "        rmse_test = item['rmse_test']\n",
    "\n",
    "        # Sort params to ensure consistency \n",
    "        # Convert to tuple to make it hashable, and so able to be used as a dictionary key \n",
    "        hashable_dynamic_params = tuple(sorted(dynamic_params_dict.items()))\n",
    "\n",
    "        # Check if combination does not exist in the dictionary\n",
    "        if hashable_dynamic_params not in grouped_scores_data:\n",
    "\n",
    "            # Create entry if not\n",
    "            grouped_scores_data[hashable_dynamic_params] = {\n",
    "                'dynamic_params': dynamic_params_dict, \n",
    "                'rmse_test': []\n",
    "            }\n",
    "        grouped_scores_data[hashable_dynamic_params]['rmse_test'].append(rmse_test)\n",
    "\n",
    "    # Calculate median for each group and format output\n",
    "    final_output = []\n",
    "    for group_info in grouped_scores_data.values():\n",
    "        combination = group_info['dynamic_params']\n",
    "        rmse_scores = group_info['rmse_test']\n",
    "\n",
    "        # Calculate median RMSE\n",
    "        median_rmse = statistics.median(rmse_scores)\n",
    "        final_output.append({\n",
    "            'dynamic_params': combination,\n",
    "            'rmse_test_median': median_rmse\n",
    "        })\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80efa210",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "820ba804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the desired dataset\n",
    "df = pd.read_csv(\"../data/sustavianfeed.csv\", sep=';')\n",
    "\n",
    "# Dropping the first column (index) and renaming the columns\n",
    "df = df.drop(columns= ['WING TAG', 'EMPTY MUSCULAR STOMACH'])\n",
    "\n",
    "# Moving crude protein to the end of the dataframe\n",
    "df = df[[col for col in df.columns if col != 'CRUDE PROTEIN'] + ['CRUDE PROTEIN']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3f831",
   "metadata": {},
   "source": [
    "# Nested CV with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47c6c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    " \n",
    "# Edit the name and log directory based on the model you want to run\n",
    "\n",
    "#MODEL_NAME = 'GP'\n",
    "#MODEL_NAME = 'GSGP'\n",
    "MODEL_NAME = 'SLIM-GSGP'\n",
    "\n",
    "DATASET_NAME = MODEL_NAME +'_sustavianfeed'\n",
    "LOG_DIR = './log/' + MODEL_NAME + '/'\n",
    "\n",
    "LOG_LEVEL = 2\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5007d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_outer = 3\n",
    "k_inner = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d600cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning df into X and y torch.Tensors\n",
    "X, y = load_pandas_df(df, X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab3d1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Instances:\t96\n",
      "--\n",
      "Outer Train set:\t64\n",
      "Test set:\t\t32\n",
      "--\n",
      "Inner Train set:\t32\n",
      "Validation set:\t\t32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FITNESS_FUNCTION = 'rmse'\n",
    "MINIMIZATION = True\n",
    "\n",
    "total_instances = X.shape[0]\n",
    "outer_test_size = total_instances // k_outer\n",
    "outer_train_size = total_instances - outer_test_size\n",
    "inner_val_size = outer_train_size // k_inner\n",
    "inner_train_size = outer_train_size - inner_val_size\n",
    "\n",
    "print(f'Total Instances:\\t{total_instances}\\n--')\n",
    "print(f'Outer Train set:\\t{outer_train_size}')\n",
    "print(f'Test set:\\t\\t{outer_test_size}\\n--')\n",
    "print(f'Inner Train set:\\t{inner_train_size}')\n",
    "print(f'Validation set:\\t\\t{inner_val_size}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fce2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 20\n",
    "\n",
    "fixed_params = {\n",
    "    # ---\n",
    "    # Search Space\n",
    "    'initializer': 'rhh',\n",
    "    'init_depth': 2,\n",
    "    'tree_constants': [random.uniform(0, 1) for _ in range(9)]+[ -1.], \n",
    "    'tree_functions': ['add', 'subtract'],\n",
    "    'prob_const': 0.1,\n",
    "    # ---\n",
    "    # Problem Instance\n",
    "    'dataset_name': DATASET_NAME,\n",
    "    'fitness_function': 'rmse',\n",
    "    'minimization': True,\n",
    "    # ---\n",
    "    # Model instance \n",
    "    'tournament_size': int(POP_SIZE*0.02) if POP_SIZE>100 else 2,\n",
    "    'pop_size': POP_SIZE,\n",
    "    'ms_lower': 0,\n",
    "    'ms_upper': 0.5,\n",
    "    'reconstruct': False,\n",
    "    # ---\n",
    "    # Solve settings\n",
    "    'n_iter': 500,\n",
    "    'elitism': True,\n",
    "    'n_elites': 2, \n",
    "    'test_elite': True,\n",
    "    'log_level': LOG_LEVEL,\n",
    "    'verbose': 0,\n",
    "    'n_jobs': 1,\n",
    "\n",
    "    # ---\n",
    "    # GP unique settings\n",
    "    #'max_depth': 10, \n",
    "    #'p_xo' : 0.5,\n",
    "\n",
    "    # ---\n",
    "    # GSGP unique settings\n",
    "    \n",
    "\n",
    "    # ---\n",
    "    # SLIM unique settings\n",
    "    'max_depth': 10,\n",
    "    'p_inflate': 0.70,\n",
    "    #'slim_version': 'SLIM+SIG2',\n",
    "    #'copy_parent': True,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "SLIM_VERSIONS = ['SLIM+SIG2', 'SLIM+SIG1', 'SLIM+ABS', 'SLIM*SIG2', 'SLIM*SIG1', 'SLIM*ABS']\n",
    "\n",
    "param_grid = {\n",
    "    'slim_version': SLIM_VERSIONS,\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5b10a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_nested_cross_validation(X, y, gp_model,  k_outer, k_inner, fixed_params, param_grid, seed, LOG_DIR, DATASET_NAME):\n",
    "    \"\"\"\n",
    "    Perform nested cross-validation for a given model and dataset.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): Feature matrix.\n",
    "        y (torch.Tensor): Target vector.\n",
    "        gp_model (callable): The gp model to be evaluated.\n",
    "        k_outer (int): Number of outer folds.\n",
    "        k_inner (int): Number of inner folds.\n",
    "        fixed_params (dict): Fixed parameters for the model.\n",
    "        param_grid (dict): Parameter grid for hyperparameter tuning.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries containing model results.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    cv_outer = KFold(n_splits=k_outer, random_state=seed, shuffle=True)\n",
    "    cv_inner = KFold(n_splits=k_inner, random_state=seed, shuffle=True)\n",
    "\n",
    "    data_cv_outer = [[learning_ix, test_ix] for learning_ix, test_ix in cv_outer.split(X, y)]\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for i, (train_ix, test_ix) in enumerate(data_cv_outer):\n",
    "        print(f'Outer fold {i+1}/{k_outer}')\n",
    "        X_learning, y_learning = X[train_ix], y[train_ix]\n",
    "        X_test, y_test = X[test_ix], y[test_ix]\n",
    "\n",
    "        # Inner cross-validation\n",
    "        results = []    \n",
    "\n",
    "        data_cv_inner = [[learning_ix, val_ix] for learning_ix, val_ix in cv_inner.split(X_learning, y_learning)]\n",
    "        for j, (train_ix, val_ix) in enumerate(data_cv_inner):\n",
    "\n",
    "            # Split the data into training and validation sets K times \n",
    "            print(f'-----\\n Inner fold {j+1}/{k_inner}')\n",
    "            X_inner_train, y_inner_train = X_learning[train_ix], y_learning[train_ix]\n",
    "            X_inner_val, y_inner_val = X_learning[val_ix], y_learning[val_ix]\n",
    "\n",
    "            print(f'Training shape: {X_inner_train.shape}\\nValidation shape: {X_inner_val.shape}\\n')\n",
    "\n",
    "            # Update the X and y values in the fixed_params dictionary\n",
    "            fixed_params.update({\n",
    "                'X_train': X_inner_train, 'y_train': y_inner_train,\n",
    "                'X_test': X_inner_val, 'y_test': y_inner_val\n",
    "            })\n",
    "\n",
    "            # Update LOG_PATH in the fixed_params dictionary\n",
    "            LOG_PATH = LOG_DIR+DATASET_NAME+'_'+'inner'+'_'+str(j)+'.csv'\n",
    "            if os.path.exists(LOG_PATH):\n",
    "                os.remove(LOG_PATH)\n",
    "            fixed_params.update({'log_path': LOG_PATH})\n",
    "\n",
    "\n",
    "            res = fit_model_GridSearch(gp_model=gp_model, fixed_params=fixed_params, param_grid=param_grid, seed=(seed+k_inner))\n",
    "            \n",
    "            # Log\n",
    "            results.append(res)\n",
    "\n",
    "        medians = group_and_median_rmse(results) \n",
    "\n",
    "        # Find minimum median rmse\n",
    "        best_dynamic_combo_median = min(medians, key=lambda x: x['rmse_test_median'])\n",
    "\n",
    "        print(f'Best inner combination: {best_dynamic_combo_median[\"dynamic_params\"]} with median RMSE: {best_dynamic_combo_median[\"rmse_test_median\"]}')\n",
    "\n",
    "        # Train the best model on the entire training set\n",
    "        print('Training best combination on entire learning set')\n",
    "\n",
    "        best_hyper_combo = best_dynamic_combo_median['dynamic_params']\n",
    "\n",
    "        fixed_params.update({\n",
    "                'X_train': X_learning, 'y_train': y_learning,\n",
    "                'X_test': X_test, 'y_test': y_test\n",
    "            })\n",
    "        \n",
    "        LOG_PATH = LOG_DIR+DATASET_NAME+'_'+'outer'+'_'+str(i)+'.csv'\n",
    "        if os.path.exists(LOG_PATH):\n",
    "            os.remove(LOG_PATH)\n",
    "    \n",
    "        fixed_params.update({'log_path': LOG_PATH})\n",
    "        \n",
    "        full_params = {**fixed_params, **best_hyper_combo}\n",
    "\n",
    "        outer_model = gp_model(**full_params, seed=(seed+k_outer))\n",
    "\n",
    "        res = {'model': outer_model}  \n",
    "        res.update({'rmse_train': outer_model.fitness.item()})\n",
    "        res.update({'rmse_test': outer_model.test_fitness.item()})\n",
    "        res.update({'dynamic_params': best_hyper_combo})\n",
    "\n",
    "        models.append(res)\n",
    "\n",
    "    return models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c07ded42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1/2\n",
      "-----\n",
      " Inner fold 1/3\n",
      "Training shape: torch.Size([32, 12])\n",
      "Validation shape: torch.Size([16, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 2/3\n",
      "Training shape: torch.Size([32, 12])\n",
      "Validation shape: torch.Size([16, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 3/3\n",
      "Training shape: torch.Size([32, 12])\n",
      "Validation shape: torch.Size([16, 12])\n",
      "\n",
      "Best inner combination: {'slim_version': 'SLIM*ABS'} with median RMSE: 11.605127334594727\n",
      "Training best combination on entire learning set\n",
      "Outer fold 2/2\n",
      "-----\n",
      " Inner fold 1/3\n",
      "Training shape: torch.Size([32, 12])\n",
      "Validation shape: torch.Size([16, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 2/3\n",
      "Training shape: torch.Size([32, 12])\n",
      "Validation shape: torch.Size([16, 12])\n",
      "\n",
      "-----\n",
      " Inner fold 3/3\n",
      "Training shape: torch.Size([32, 12])\n",
      "Validation shape: torch.Size([16, 12])\n",
      "\n",
      "Best inner combination: {'slim_version': 'SLIM*SIG2'} with median RMSE: 13.621261596679688\n",
      "Training best combination on entire learning set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': <slim_gsgp.algorithms.SLIM_GSGP.representations.individual.Individual at 0x277dbe1f960>,\n",
       "  'rmse_train': 9.929572105407715,\n",
       "  'rmse_test': 10.63968563079834,\n",
       "  'dynamic_params': {'slim_version': 'SLIM*ABS'}},\n",
       " {'model': <slim_gsgp.algorithms.SLIM_GSGP.representations.individual.Individual at 0x277dbe1d7b0>,\n",
       "  'rmse_train': 10.159979820251465,\n",
       "  'rmse_test': 10.654454231262207,\n",
       "  'dynamic_params': {'slim_version': 'SLIM*SIG2'}}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_nested_cross_validation(X, y, gp_model=slim, k_outer=2, k_inner=3, fixed_params=fixed_params, param_grid=param_grid, seed=seed, LOG_DIR=LOG_DIR, DATASET_NAME=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576c88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ffd5a2f",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "8be44f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from plotly.subplots import make_subplots\n",
    "import ast  \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "addb8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../log/gp.csv\", header=None)\n",
    "settings_df = pd.read_csv(\"../log/gp_settings.csv\", header=None)\n",
    "unique_settings_df = settings_df.drop_duplicates(0) #the comb id is now indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "3df47a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>865732c8-3014-11f0-b37b-baa0ecd080fe</td>\n",
       "      <td>{'log': 1, 'verbose': 0, 'test_elite': True, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8f386164-3014-11f0-b37b-baa0ecd080fe</td>\n",
       "      <td>{'log': 1, 'verbose': 0, 'test_elite': True, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9498ad58-3014-11f0-b37b-baa0ecd080fe</td>\n",
       "      <td>{'log': 1, 'verbose': 0, 'test_elite': True, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9cac4a04-3014-11f0-b37b-baa0ecd080fe</td>\n",
       "      <td>{'log': 1, 'verbose': 0, 'test_elite': True, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a37fb898-3014-11f0-b37b-baa0ecd080fe</td>\n",
       "      <td>{'log': 1, 'verbose': 0, 'test_elite': True, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0  \\\n",
       "0  865732c8-3014-11f0-b37b-baa0ecd080fe   \n",
       "1  8f386164-3014-11f0-b37b-baa0ecd080fe   \n",
       "2  9498ad58-3014-11f0-b37b-baa0ecd080fe   \n",
       "3  9cac4a04-3014-11f0-b37b-baa0ecd080fe   \n",
       "4  a37fb898-3014-11f0-b37b-baa0ecd080fe   \n",
       "\n",
       "                                                   1  \n",
       "0  {'log': 1, 'verbose': 0, 'test_elite': True, '...  \n",
       "1  {'log': 1, 'verbose': 0, 'test_elite': True, '...  \n",
       "2  {'log': 1, 'verbose': 0, 'test_elite': True, '...  \n",
       "3  {'log': 1, 'verbose': 0, 'test_elite': True, '...  \n",
       "4  {'log': 1, 'verbose': 0, 'test_elite': True, '...  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_settings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0  - Algorithm\n",
    "# 1  - Instance ID\n",
    "# 2  - Dataset\n",
    "# 3  - Seed\n",
    "# 4  - Generation\n",
    "# 5  - Fitness\n",
    "# 6  - Running time\n",
    "# 7  - Population nodes\n",
    "# 8  - Test fitness\n",
    "# 9  - Elite nodes\n",
    "# 10 - niche entropy\n",
    "\"\"\"From here on, it doesnt appear on df\"\"\"\n",
    "# 11 - sd(pop.fit)\n",
    "# 12 - Log level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb68776",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_combination_str(setting_str, unique_settings_df = pd.DataFrame(df[1].unique())):\n",
    "    comb_str = unique_settings_df[unique_settings_df[0]==setting_str][1][0]\n",
    "    return comb_str'''\n",
    "\n",
    "def param_in_combination(param:str, comb_str: str):\n",
    "    \"\"\"\n",
    "    Parameters that the function can receive:\n",
    "    'log' / 'verbose'/ 'test_elite' / 'n_jobs' / 'max_depth' / 'n_elites' / 'elistism' / 'n_iter' \n",
    "    'settings_dict' / 'p_xo' / 'pop_size' / 'seed' / 'p_m' / 'p_c' / 'init_depth' / 'init_pop_size'\n",
    "    \"\"\"\n",
    "    variable_init = comb_str.find(param) \n",
    "    param_init = variable_init + len(param) + 3 #advance 3 steps to account for the quote, the dots and the space. \n",
    "    param_end = comb_str.find(',', variable_init)\n",
    "    param_value = comb_str[param_init:param_end]\n",
    "    if param_value.startswith('<') or param_value.startswith('['):\n",
    "        print('The value of the parameter given cannot be converted to its original class:')\n",
    "    else:\n",
    "        try:\n",
    "            return ast.literal_eval(param_value)\n",
    "        except SyntaxError as s:\n",
    "            print(f'Parameter does not exist in the combination string or it cannot be accessed. ({s})')\n",
    "\n",
    "#example\n",
    "#print(get_combination_str('865732c8-3014-11f0-b37b-baa0ecd080fe'))\n",
    "#print(param_in_combination('log', get_combination_str('865732c8-3014-11f0-b37b-baa0ecd080fe')))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a37af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def pop_fitness_diversity(df, train_color='blue'):\n",
    "     \"\"\"\n",
    "     Out of Bounds\n",
    "     \"\"\"\n",
    "     dif_combs = np.unique(df[[1]])\n",
    "     for comb in dif_combs:\n",
    "          y = df[df[1]==comb]\n",
    "          #comb_dict = get_combination(comb)\n",
    "          fig = go.Figure()\n",
    "          fig.add_trace(go.Scatter(y=y.iloc[:,11].values, \n",
    "                                   mode='lines', name='Train', line=dict(color=train_color)))\n",
    "          fig.update_layout(\n",
    "          height=400, width=800, \n",
    "          margin=dict(t=50),\n",
    "          yaxis_range=[0,None],\n",
    "          title_text=f'GP - Population Fitness Diversity\\nCombination:',\n",
    "          xaxis_title='Generation', yaxis_title='Fitness Standard Deviation'\n",
    "          )\n",
    "          fig.show()'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "d2a45840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_fit(df, train_color='blue', test_color='orange', rows=5, cols=4):\n",
    "    dif_combs = df[1].unique()  # Get unique combinations\n",
    "    unique_setting_df = pd.DataFrame(dif_combs)\n",
    "    num_plots = len(dif_combs)\n",
    "    assert rows*cols==num_plots\n",
    "    \n",
    "    # Create subplot grid\n",
    "    fig = sp.make_subplots(rows=rows, cols=cols, \n",
    "                           subplot_titles=[f\"Combination index: {unique_settings_df[unique_settings_df[0]==comb].index[0]}\" \n",
    "                                           for comb in dif_combs])\n",
    "    \n",
    "    for i, comb in enumerate(dif_combs):\n",
    "        y = df[df[1] == comb]\n",
    "        algo = y.iloc[0,0]\n",
    "        row = (i // cols) + 1  #Calculate row position\n",
    "        col = (i % cols) + 1   #Calculate column position\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=y.iloc[:, 5].values, mode='lines', name='Train', line=dict(color=train_color),\n",
    "                       showlegend=(i==0)),\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=y.iloc[:, 8].values, mode='lines', name='Test', line=dict(color=test_color),\n",
    "                       showlegend=(i==0)),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(range=[0, None], row=row, col=col)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=150 * rows,\n",
    "        width=250 * cols,\n",
    "        margin=dict(t=50),\n",
    "        title_text=f'{algo} - Train vs Test Fitness (x=Generation, y=RMSE)',\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.update_annotations(font_size=10)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "a1a375f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_fit_and_size(df, comb_idxs: list | int = [i for i in range(pd.DataFrame(df[1].unique()).shape[0])],\n",
    "                            train_color='blue', test_color='orange'):\n",
    "     unique_setting_df = pd.DataFrame(df[1].unique())\n",
    "     for comb_idx in comb_idxs:\n",
    "          comb = unique_settings_df.iloc[comb_idx, 0]\n",
    "          y = df[df[1]==comb]\n",
    "          algo = y.iloc[0,0]\n",
    "          fig = make_subplots(\n",
    "          rows=1, cols=2,\n",
    "          subplot_titles=(f'{algo} - Fitness evolution\\nCombination:', f'{algo} - Size evolution')\n",
    "          )\n",
    "\n",
    "          fig.add_trace(go.Scatter(y=y.iloc[:,5].values, \n",
    "                                   mode='lines', name='Train', line=dict(color=train_color)), row=1, col=1)\n",
    "          fig.add_trace(go.Scatter(y=y.iloc[:,8].values, \n",
    "                                   mode='lines', name='Test', line=dict(color=test_color)), row=1, col=1)\n",
    "          fig.add_trace(go.Scatter(y=y.iloc[:,9].values, \n",
    "                                   mode='lines', name='Size'), row=1, col=2)\n",
    "          \n",
    "          fig.update_xaxes(title_text=\"Generation\")\n",
    "\n",
    "          fig.update_layout(\n",
    "          width=1000,\n",
    "          height=400, \n",
    "          showlegend=True,\n",
    "          yaxis_range=[0,None],\n",
    "          )\n",
    "          fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "f6bfe576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def niche_entropy(df, train_color='blue', rows=5, cols=4):\n",
    "    dif_combs = df[1].unique()  # Get unique combinations\n",
    "    unique_setting_df = pd.DataFrame(dif_combs) # array to df\n",
    "    num_plots = len(dif_combs)\n",
    "    assert rows*cols==num_plots, \"The number of combinations does not correspond to the grid size defined (rows/cols).\"\n",
    "\n",
    "    fig = sp.make_subplots(rows=rows, cols=cols, \n",
    "                           subplot_titles=[f\"Combination index: {unique_settings_df[unique_settings_df[0]==comb].index[0]}\" \n",
    "                                           for comb in dif_combs])\n",
    "\n",
    "    for i, comb in enumerate(dif_combs):\n",
    "        y = df[df[1] == comb]\n",
    "        algo = y.iloc[0,0]\n",
    "        row = (i // cols) + 1\n",
    "        col = (i % cols) + 1\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                y=y.iloc[:, 10].values,\n",
    "                mode='lines',\n",
    "                name='Niche Entropy',\n",
    "                line=dict(color=train_color),\n",
    "                showlegend=(i == 0)), row=row, col=col\n",
    "                )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=150 * rows,\n",
    "        width=250 * cols,\n",
    "        margin=dict(t=50),\n",
    "        title_text=f'{algo} - Niche Entropy (x=Generation, y=Entropy)',\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "abe9fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combs_together_test(df, comb_idxs: list | int = [i for i in range(pd.DataFrame(df[1].unique()).shape[0])],\n",
    "                             colors = ['#FF0000', '#0000FF', '#00FF00', '#FFA500', '#800080', \n",
    "                                       '#FF00FF', '#00FFFF', '#FFFF00', '#1F77B4', '#FF7F0E',\n",
    "                                       '#2CA02C', '#D62728', '#9467BD', '#8C564B', '#E377C2',\n",
    "                                       '#7F7F7F', '#AEC7E8', '#FFBB78', '#98DF8A', '#FF9896'],\n",
    "                              ):\n",
    "     \n",
    "     assert len(colors)>=len(comb_idxs), \"Not enough colors for all combinations\"\n",
    "\n",
    "     unique_settings_df = pd.DataFrame(df[1].unique())\n",
    "     fig = go.Figure()\n",
    "     for i, comb_idx in enumerate(comb_idxs):\n",
    "          comb = unique_settings_df.iloc[comb_idx, 0]\n",
    "          y = df[df[1]==comb]\n",
    "          algo = y.iloc[0,0]\n",
    "\n",
    "          fig.add_trace(go.Scatter(y=y.iloc[:,8].values, \n",
    "                                   mode='lines', name=f'Test Comb {comb_idx}',\n",
    "                                   line=dict(color=colors[i])))#, row=1, col=1)\n",
    "          \n",
    "          fig.update_xaxes(title_text=\"Generation\")\n",
    "\n",
    "     fig.update_layout(\n",
    "          width=1000,\n",
    "          height=400, \n",
    "          title_text = f\"{algo} - Test Fitness (Combinations indexes: {comb_idxs})\",\n",
    "          showlegend=True,\n",
    "          yaxis_range=[0,None],\n",
    "          )\n",
    "     \n",
    "     fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98572ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9910b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_fit_and_size(df, comb_idxs=[3,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "niche_entropy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_combs_together_test(df,comb_idxs=[1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16023f",
   "metadata": {},
   "source": [
    "Modular functions for different versions/hyperparameters combinations\n",
    "ASSUMING THAT:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIM_VERSIONS = ['SLIM+SIG2', 'SLIM+SIG1', 'SLIM+ABS', 'SLIM*SIG2', 'SLIM*SIG1', 'SLIM*ABS']\n",
    "COMBINATIONS = [ for i in df[1].unique()]\n",
    "\n",
    "\"\"\"param_grid = {\n",
    "    'slim_version': SLIM_VERSIONS\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390510b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_by_config = defaultdict(list)\n",
    "\n",
    "for split in results:\n",
    "    rmse_train = []\n",
    "    rmse_test = []\n",
    "    \n",
    "    for result in split:\n",
    "        key = ''\n",
    "        for k, v in result['dynamic_params'].items():\n",
    "            key += k+': '+str(v)+' <br /> '\n",
    "        rmse_by_config[key].append(result['rmse_test'])\n",
    "\n",
    "fig = go.Figure()\n",
    "for config, rmse_values in rmse_by_config.items():\n",
    "    fig.add_trace(go.Box(\n",
    "        y=rmse_values,\n",
    "        boxpoints='all',\n",
    "        jitter=0.5,\n",
    "        pointpos=0,\n",
    "        line=dict(color='orange'),\n",
    "        name=config\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=DATASET_NAME+' dataset',\n",
    "    xaxis_title='',\n",
    "    yaxis_title='Test RMSE',\n",
    "    height=500, width=1100,\n",
    "    xaxis_tickangle=-90,\n",
    "    yaxis_range=[0,None],\n",
    "    margin=dict(l=50, r=50, t=50, b=20),\n",
    "    showlegend=False,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd428207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "df_log = []\n",
    "for i_inner in range(k_inner):\n",
    "    tmp = pd.read_csv(LOG_DIR+'slim_'+DATASET_NAME+'_'+str(i_inner)+'.csv', header=None)\n",
    "    tmp['cv'] = i_inner\n",
    "    df_log.append(tmp)\n",
    "df_log = pd.concat(df_log, ignore_index=True)\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_evolution_plots(n_rows, n_cols, SLIM_VERSIONS, df_log,\n",
    "                     plot_title = 'SLIM - Train vs Test Fitness ('+DATASET_NAME+' dataset)')\n",
    "[fixed_params['pop_size'], fixed_params['tournament_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_evolution_plots(n_rows, n_cols, SLIM_VERSIONS, df_log, var='size'\n",
    "                     plot_title = 'SLIM -Size ('+DATASET_NAME+' dataset)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
